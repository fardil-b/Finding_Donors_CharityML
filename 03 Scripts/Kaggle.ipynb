{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ce9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from IPython.display import display \n",
    "\n",
    "# Read the train and test data\n",
    "train = pd.read_csv('census.csv')\n",
    "test = pd.read_csv('test_census.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5586e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['age', 'workclass', 'education_level', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
      "Test columns: ['age', 'workclass', 'education_level', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "# Print train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d54a77",
   "metadata": {},
   "source": [
    "Remember, that the test dataset generally contains one column less than the train one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be7d13",
   "metadata": {},
   "source": [
    "> Get familiar with the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826702f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  income\n",
      "0   0       1\n",
      "1   1       1\n",
      "2   2       1\n",
      "3   3       1\n",
      "4   4       1\n"
     ]
    }
   ],
   "source": [
    "# Read the sample submission file\n",
    "sample_submission = pd.read_csv('example_submission.csv')\n",
    "\n",
    "# Look at the head() of the sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634b772",
   "metadata": {},
   "source": [
    "The sample submission file consists of two columns: id of the observation and income column for your predictions. Kaggle will evaluate your predictions on the true income data for the corresponding id. So, itâ€™s important to keep track of the predictions by id before submitting them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee80fca",
   "metadata": {},
   "source": [
    "## Fist Determine the problem type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba5fb7",
   "metadata": {},
   "source": [
    "Before building a model, you should determine the problem type you are addressing. Look at the distribution of the target variable, and select the correct problem type you will be building a model for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be550cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAU9ElEQVR4nO3dbaxd1Z3f8e8vxgTENGMn0FvXRrEljKZO1AFyBU6nL26JAgaNaiJRC9oJHkLjZALVZBpFgVQKMxDUyUgZNGgIqiM8mDYTx8Mkg0FmHJfhaJoXgCEhgCGEW5wUm6cG85AbijOGf1+c5fbEXN9zfO6Dsfh+pK27z3+vtc7avNg/733WOaSqkCS9s73rSE9AknTkGQaSJMNAkmQYSJIwDCRJwDFHegLDOvHEE2vp0qVD9f3FL37BCSecMLMTkqQ5MN3r14MPPvizqjrp4PpRGwZLly7lgQceGKpvp9NhbGxsZickSXNgutevJD+drN73MVGS45Lcn+SHSXYm+aNWvyXJriQPte20Vk+SG5KMJ3k4yRk9Y61N8mTb1vbUP5TkkdbnhiQZ+kwlSYdtkDuDfcDZVTWRZD7wvSR3tWOfr6rbDmp/HrC8bWcBNwFnJXkvcDUwChTwYJItVfVSa/NJ4D5gK7AKuAtJ0pzoe2dQXRPt5fy2TfW15dXAra3fvcCCJIuAc4HtVbW3BcB2YFU79p6qure6X4e+Fbhg+FOSJB2ugT4zSDIPeBA4Bbixqu5L8nvAdUm+BNwNXFlV+4DFwNM93Xe32lT13ZPUJ5vHOmAdwMjICJ1OZ5Dpv8XExMTQfSXpSJqt69dAYVBVbwCnJVkAfCfJB4GrgOeAY4H1wBeAa2Z8hr86j/XtvRgdHa1hP0TxA2RJR6vZun4d1vcMqupl4B5gVVU92x4F7QP+AjizNdsDnNzTbUmrTVVfMkldkjRHBllNdFK7IyDJ8cBHgR+1Z/20lT8XAI+2LluAS9qqopXAK1X1LLANOCfJwiQLgXOAbe3Yq0lWtrEuAW6fyZOUJE1tkMdEi4CN7XODdwGbq+rOJH+X5CQgwEPAp1v7rcD5wDjwGnApQFXtTXItsKO1u6aq9rb9zwC3AMfTXUXkSiJJmkN9w6CqHgZOn6R+9iHaF3D5IY5tADZMUn8A+GC/uUiSZsdR+w3k6Xjh5/u4fvuP+7b7g4+eOgezkaQjzx+qkyQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYoAwSHJckvuT/DDJziR/1OrLktyXZDzJt5Ic2+rvbq/H2/GlPWNd1epPJDm3p76q1caTXDkL5ylJmsIgdwb7gLOr6jeB04BVSVYCXwGur6pTgJeAy1r7y4CXWv361o4kK4CLgA8Aq4CvJZmXZB5wI3AesAK4uLWVJM2RvmFQXRPt5fy2FXA2cFurbwQuaPur22va8Y8kSatvqqp9VbULGAfObNt4VT1VVb8ENrW2kqQ5cswgjdq/3h8ETqH7r/j/CbxcVftbk93A4ra/GHgaoKr2J3kFeF+r39szbG+fpw+qn3WIeawD1gGMjIzQ6XQGmf5bzH9zH4tf39W3XafzzFDjS9JsmZiYGPraN5WBwqCq3gBOS7IA+A7wGzM+k8HmsR5YDzA6OlpjY2NDjbP5jm3sOW5Z33Zrxk4danxJmi2dTodhr31TOazVRFX1MnAP8GFgQZIDYbIE2NP29wAnA7Tjvw682Fs/qM+h6pKkOTLIaqKT2h0BSY4HPgo8TjcULmzN1gK3t/0t7TXt+N9VVbX6RW210TJgOXA/sANY3lYnHUv3Q+YtM3BukqQBDfKYaBGwsX1u8C5gc1XdmeQxYFOSLwM/AG5u7W8G/muScWAv3Ys7VbUzyWbgMWA/cHl7/ESSK4BtwDxgQ1XtnLEzlCT11TcMquph4PRJ6k/RXQl0cP114N8cYqzrgOsmqW8Ftg4wX0nSLPAbyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQGCIMkJye5J8ljSXYm+f1W/8Mke5I81Lbze/pclWQ8yRNJzu2pr2q18SRX9tSXJbmv1b+V5NiZPlFJ0qENcmewH/hcVa0AVgKXJ1nRjl1fVae1bStAO3YR8AFgFfC1JPOSzANuBM4DVgAX94zzlTbWKcBLwGUzdH6SpAH0DYOqeraqvt/2fw48DiyeostqYFNV7auqXcA4cGbbxqvqqar6JbAJWJ0kwNnAba3/RuCCIc9HkjSEw/rMIMlS4HTgvla6IsnDSTYkWdhqi4Gne7rtbrVD1d8HvFxV+w+qS5LmyDGDNkzya8BfA5+tqleT3ARcC1T7+1XgE7Myy/8/h3XAOoCRkRE6nc5Q48x/cx+LX9/Vt12n88xQ40vSbJmYmBj62jeVgcIgyXy6QfCNqvo2QFU933P868Cd7eUe4OSe7ktajUPUXwQWJDmm3R30tv8VVbUeWA8wOjpaY2Njg0z/LTbfsY09xy3r227N2KlDjS9Js6XT6TDstW8qg6wmCnAz8HhV/WlPfVFPs48Bj7b9LcBFSd6dZBmwHLgf2AEsbyuHjqX7IfOWqirgHuDC1n8tcPv0TkuSdDgGuTP4LeDjwCNJHmq1L9JdDXQa3cdEPwE+BVBVO5NsBh6juxLp8qp6AyDJFcA2YB6woap2tvG+AGxK8mXgB3TDR5I0R/qGQVV9D8gkh7ZO0ec64LpJ6lsn61dVT9FdbSRJOgL8BrIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxABhkOTkJPckeSzJziS/3+rvTbI9yZPt78JWT5IbkowneTjJGT1jrW3tn0yytqf+oSSPtD43JMlsnKwkaXKD3BnsBz5XVSuAlcDlSVYAVwJ3V9Vy4O72GuA8YHnb1gE3QTc8gKuBs4AzgasPBEhr88mefqumf2qSpEH1DYOqeraqvt/2fw48DiwGVgMbW7ONwAVtfzVwa3XdCyxIsgg4F9heVXur6iVgO7CqHXtPVd1bVQXc2jOWJGkOHHM4jZMsBU4H7gNGqurZdug5YKTtLwae7um2u9Wmqu+epD7Z+6+je7fByMgInU7ncKb//8x/cx+LX9/Vt12n88xQ40vSbJmYmBj62jeVgcMgya8Bfw18tqpe7X2sX1WVpGZ8dgepqvXAeoDR0dEaGxsbapzNd2xjz3HL+rZbM3bqUONL0mzpdDoMe+2bykCriZLMpxsE36iqb7fy8+0RD+3vC62+Bzi5p/uSVpuqvmSSuiRpjgyymijAzcDjVfWnPYe2AAdWBK0Fbu+pX9JWFa0EXmmPk7YB5yRZ2D44PgfY1o69mmRle69LesaSJM2BQR4T/RbwceCRJA+12heBPwY2J7kM+Cmwph3bCpwPjAOvAZcCVNXeJNcCO1q7a6pqb9v/DHALcDxwV9skSXOkbxhU1feAQ637/8gk7Qu4/BBjbQA2TFJ/APhgv7lIkmaH30CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkMUAYJNmQ5IUkj/bU/jDJniQPte38nmNXJRlP8kSSc3vqq1ptPMmVPfVlSe5r9W8lOXYmT1CS1N8gdwa3AKsmqV9fVae1bStAkhXARcAHWp+vJZmXZB5wI3AesAK4uLUF+Eob6xTgJeCy6ZyQJOnw9Q2Dqvp7YO+A460GNlXVvqraBYwDZ7ZtvKqeqqpfApuA1UkCnA3c1vpvBC44vFOQJE3XMdPoe0WSS4AHgM9V1UvAYuDenja7Ww3g6YPqZwHvA16uqv2TtH+LJOuAdQAjIyN0Op2hJj7/zX0sfn1X33adzjNDjS9Js2ViYmLoa99Uhg2Dm4BrgWp/vwp8YqYmdShVtR5YDzA6OlpjY2NDjbP5jm3sOW5Z33Zrxk4danxJmi2dTodhr31TGSoMqur5A/tJvg7c2V7uAU7uabqk1ThE/UVgQZJj2t1Bb3tJ0hwZamlpkkU9Lz8GHFhptAW4KMm7kywDlgP3AzuA5W3l0LF0P2TeUlUF3ANc2PqvBW4fZk6SpOH1vTNI8k1gDDgxyW7gamAsyWl0HxP9BPgUQFXtTLIZeAzYD1xeVW+0ca4AtgHzgA1VtbO9xReATUm+DPwAuHmmTk6SNJi+YVBVF09SPuQFu6quA66bpL4V2DpJ/Sm6q40kSUeI30CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiQH+t5eSpNl3/fYfD9Tu9Pmz8/7eGUiSDANJkmEgSWKAMEiyIckLSR7tqb03yfYkT7a/C1s9SW5IMp7k4SRn9PRZ29o/mWRtT/1DSR5pfW5Ikpk+SUnS1Aa5M7gFWHVQ7Urg7qpaDtzdXgOcByxv2zrgJuiGB3A1cBZwJnD1gQBpbT7Z0+/g95IkzbK+YVBVfw/sPai8GtjY9jcCF/TUb62ue4EFSRYB5wLbq2pvVb0EbAdWtWPvqap7q6qAW3vGkiTNkWGXlo5U1bNt/zlgpO0vBp7uabe71aaq756kPqkk6+jecTAyMkKn0xlq8vPf3Mfi13f1bdfpPDPU+JJ0uBa/vm+gdhP7/mHoa99Upv09g6qqJDUTkxngvdYD6wFGR0drbGxsqHE237GNPcct69tuzdipQ40vSYdr8O8ZPMOw176pDLua6Pn2iIf294VW3wOc3NNuSatNVV8ySV2SNIeGDYMtwIEVQWuB23vql7RVRSuBV9rjpG3AOUkWtg+OzwG2tWOvJlnZVhFd0jOWJGmO9H1MlOSbwBhwYpLddFcF/TGwOcllwE+BNa35VuB8YBx4DbgUoKr2JrkW2NHaXVNVBz6U/gzdFUvHA3e1TZI0h/qGQVVdfIhDH5mkbQGXH2KcDcCGSeoPAB/sNw9J0uzxG8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkphkGSX6S5JEkDyV5oNXem2R7kifb34WtniQ3JBlP8nCSM3rGWdvaP5lk7fROSZJ0uGbizuBfVdVpVTXaXl8J3F1Vy4G722uA84DlbVsH3ATd8ACuBs4CzgSuPhAgkqS5MRuPiVYDG9v+RuCCnvqt1XUvsCDJIuBcYHtV7a2ql4DtwKpZmJck6RCOmWb/Ar6bpID/UlXrgZGqerYdfw4YafuLgad7+u5utUPV3yLJOrp3FYyMjNDpdIaa9Pw397H49V1923U6zww1viQdrsWv7xuo3cS+fxj62jeV6YbBv6yqPUn+MbA9yY96D1ZVtaCYES1s1gOMjo7W2NjYUONsvmMbe45b1rfdmrFThxpfkg7X9dt/PFC70+c/w7DXvqlM6zFRVe1pf18AvkP3mf/z7fEP7e8Lrfke4OSe7kta7VB1SdIcGToMkpyQ5B8d2AfOAR4FtgAHVgStBW5v+1uAS9qqopXAK+1x0jbgnCQL2wfH57SaJGmOTOcx0QjwnSQHxvnLqvrbJDuAzUkuA34KrGnttwLnA+PAa8ClAFW1N8m1wI7W7pqq2juNeUmSDtPQYVBVTwG/OUn9ReAjk9QLuPwQY20ANgw7F0nS9PgNZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJt1EYJFmV5Ikk40muPNLzkaR3krdFGCSZB9wInAesAC5OsuLIzkqS3jneFmEAnAmMV9VTVfVLYBOw+gjPSZLeMY450hNoFgNP97zeDZx1cKMk64B17eVEkieGfL8TgZ/1a/QfhxxckmbRQNevKbx/suLbJQwGUlXrgfXTHSfJA1U1OgNTkqQ5NVvXr7fLY6I9wMk9r5e0miRpDrxdwmAHsDzJsiTHAhcBW47wnCTpHeNt8ZioqvYnuQLYBswDNlTVzll8y2k/apKkI2RWrl+pqtkYV5J0FHm7PCaSJB1BhoEk6Z0XBknGkryS5KG2fann2KQ/iZGkk2S07S9L8mSSc4/E/CW9syS5JcmunmvWaa2eJDe069XDSc5o9aVJHu3p/8kkDyZZONX7vC0+QJ6utgJpflX9YsAu/6OqfvugMQ78JMZH6X7pbUeSLVX1WE+bJcDfAp+rqm0zM3tJ72RJFlbVS32afb6qbjuodh6wvG1nATdx0Jd1k3wc+A/A2f3e46i+M0jyz5J8FXgCOHWaw/X7SYxFwHeB/1RVLnuVNFMeSPKNJGcnyWH0Ww3cWl33AguSLDpwMMka4ErgnKrq+43loy4MkpyQ5NIk3wO+DjwG/POq+kE7fn3P7VTv1vtLqB9O8sMkdyX5QKtN9pMYi3tebwT+fJJ0lqTpOBX4JnAF8FiSLyb5pwe1ua49Cro+ybtbbapr1vuBP6cbBM8NMomj8THRs8DDwL+vqh8dfLCq/qBP/+8D76+qiSTnA39D9zarn/8O/E6SW6rqtcOcsyRNqqreAO4E7kxyEvCfgf+V5F9U1f3AVcBzwLF0v2PwBeCaPsP+b2AvsAa4fpB5HHV3BsCFdH+q4ttJvpTkV350qd+dQVW9WlUTbX8rMD/JifT/SYw/oftN6b9KcjSGqKS3qSS/nuRTdH95YTnwCbr/6KWqnm2PgvYBf0H3kTZMfc16DTgf+HSSfzfIHI66i1pVfRf4bpL3Ab8D3J7kZ3TvFH7S784gyT8Bnq+qSnIm3UB8EXiZ9pMYdP+DXgT824O6fxb4S+DmJL9bfmNP0jQl+W/Ah4G/Ai6pqicPOr6oqp5tnydcABxYKbQFuCLJJrofHL/S2i0FqKoXkqwCOkl+1m/Ry1EXBgdU1YvAnwF/1i7qbwzY9ULg95LsB/4PcFG7qPf9SYwWIGvp3tL9CfD5mTkbSe9gm4Hfrar9hzj+jfb4KMBDwKdbfSvdf/2P070TuPTgjlW1K8m/BrYm+Vh77DQpf45CknRUfmYgSZphhoEkyTCQJBkGkiQMA0kShoEkCcNAkgT8Xz00nN9aWEF8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot a histogram\n",
    "train.income.hist(bins=30, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b5908",
   "metadata": {},
   "source": [
    "we can see it is a classification problem, as output is categorical (either <=50k or >50k) \n",
    "- If continous, the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243cb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662dc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = train['income']\n",
    "features_raw = train.drop('income', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351a8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a10d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdbc972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "income = income_raw.apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c4ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791d814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = start - end\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fcb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd9961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier trained on 361 samples.\n",
      "RandomForestClassifier trained on 3617 samples.\n",
      "RandomForestClassifier trained on 36177 samples.\n",
      "GradientBoostingClassifier trained on 361 samples.\n",
      "GradientBoostingClassifier trained on 3617 samples.\n",
      "GradientBoostingClassifier trained on 36177 samples.\n",
      "[01:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 361 samples.\n",
      "[01:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 3617 samples.\n",
      "[01:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 36177 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = RandomForestClassifier(random_state=10)\n",
    "clf_B = GradientBoostingClassifier(random_state=10)\n",
    "clf_C = xgb.XGBClassifier(random_state=10)\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "# HINT: samples_1 is 1% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)/10)\n",
    "samples_1 = int(len(y_train)/100)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e50c0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_656/2683985395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mgrid_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Get the estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer, r2_score, fbeta_score\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = xgb.XGBClassifier(random_state=10)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {\n",
    "    \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "    \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "    \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "    \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer, n_jobs=10)\n",
    "# grid_obj=RandomizedSearchCV(clf,param_distributions=parameters,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
    "\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46650e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_clf = xgb.XGBClassifier(learning_rate = 0.2, \n",
    "                            n_estimators = 400,\n",
    "                           min_child_weight= 1,\n",
    "                           max_depth = 5,\n",
    "                           gamma = 0.2,\n",
    "                           max_delta_step = 1,\n",
    "                           colsample_bytree= 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a645865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.8725262576008844\n",
      "AUC:  0.9304468181034596\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "xg_clf.fit(X_train,y_train)\n",
    "preds = xg_clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, preds))\n",
    "print(\"AUC: \", roc_auc_score(y_test, xg_clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32f0b5",
   "metadata": {},
   "source": [
    "##  Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5ea6af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age          workclass education_level  education-num  \\\n",
       "0  21.0            Private            10th            6.0   \n",
       "1  49.0            Private       Bachelors           13.0   \n",
       "2  44.0   Self-emp-not-inc      Assoc-acdm           12.0   \n",
       "3  34.0            Private       Bachelors           13.0   \n",
       "4  24.0            Private         HS-grad            9.0   \n",
       "\n",
       "        marital-status          occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse        Craft-repair      Husband   White     Male   \n",
       "1   Married-civ-spouse        Adm-clerical         Wife   White   Female   \n",
       "2   Married-civ-spouse       Other-service         Wife   White   Female   \n",
       "3   Married-civ-spouse               Sales      Husband   White     Male   \n",
       "4   Married-civ-spouse   Machine-op-inspct      Husband   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0           0.0           0.0            40.0   United-States  \n",
       "1           0.0           0.0            40.0   United-States  \n",
       "2           0.0           0.0            99.0   United-States  \n",
       "3        7298.0           0.0            46.0   United-States  \n",
       "4           0.0           0.0            40.0   United-States  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0f324ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = test)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62cd4a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.73768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438356</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.369863</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232877</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.095890</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.054795            Private            10th       0.333333   \n",
       "1  0.438356            Private       Bachelors       0.800000   \n",
       "2  0.369863   Self-emp-not-inc      Assoc-acdm       0.733333   \n",
       "3  0.232877            Private       Bachelors       0.800000   \n",
       "4  0.095890            Private         HS-grad       0.533333   \n",
       "\n",
       "        marital-status          occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse        Craft-repair      Husband   White     Male   \n",
       "1   Married-civ-spouse        Adm-clerical         Wife   White   Female   \n",
       "2   Married-civ-spouse       Other-service         Wife   White   Female   \n",
       "3   Married-civ-spouse               Sales      Husband   White     Male   \n",
       "4   Married-civ-spouse   Machine-op-inspct      Husband   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0       0.73768           0.0        0.397959   United-States  \n",
       "1       0.00000           0.0        0.397959   United-States  \n",
       "2       0.00000           0.0        1.000000   United-States  \n",
       "3       0.00000           0.0        0.459184   United-States  \n",
       "4       0.00000           0.0        0.397959   United-States  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88f117fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = pd.get_dummies(features_log_minmax_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7364160",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_preds = xg_clf.predict_proba(features_final)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da443292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.772228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.228667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.781104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    income\n",
       "0   0  0.006017\n",
       "1   1  0.772228\n",
       "2   2  0.228667\n",
       "3   3  0.781104\n",
       "4   4  0.045826"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.DataFrame(list(xg_preds), columns = ['income'])\n",
    "final = final.reset_index()\n",
    "final.rename(columns={\"index\":\"id\"}, inplace = True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3501572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc1b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9cc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f662a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebfea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e06f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
